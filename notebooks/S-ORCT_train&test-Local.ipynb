{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "A notebook to deal with Training and Testing Analysis of S-ORCT: regularized version of ORCT. In this notebook the function which express a local regularization term is taken from _\"Sparsity in Optimal Randomized Classification Trees\"_ (Blanquero et Al. 2018)\n",
    "\n",
    "### Remark\n",
    "* We use data from Iris dataset: for a generalized version to manage any kind of datasets look at notebook 'Analysis with Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from functools import reduce # Valid in Python 2.6+, required in Python 3\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of dataset\n",
    "Let's load the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('... .csv') #IrisCategorical.csv\n",
    "iris = iris.drop('Id', axis=1)\n",
    "iris_std = iris.copy()\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # also MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0       0.222222         0.625       0.067797      0.041667        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing: we get the columns names of features which have to be standardized\n",
    "columns_names = list(iris)\n",
    "index_features = list(range(0,len(iris_std.columns)-1))\n",
    "\n",
    "#The name of the classes K\n",
    "classes = iris_std['Species'].unique().tolist()\n",
    "classes_en = [i for i in range(len(classes))] \n",
    "\n",
    "#Encoder processing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(iris_std['Species'])\n",
    "\n",
    "iris_std['Species'] = le.transform(iris_std['Species']) \n",
    "\n",
    "#Scaling phase\n",
    "iris_std[columns_names[0:4]] = scaler.fit_transform(iris_std[columns_names[0:4]])\n",
    "\n",
    "iris_std.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset between __Training & Testing Sets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris_std[columns_names[:-1]]\n",
    "y = iris_std[columns_names[4]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25)\n",
    "df_train = pd.concat([X_train, y_train], axis=1, join_axes=[X_train.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects useful to deal with trees (of depth 2) and their topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_in_NL_R = {4:[],5:[2],6:[1],7:[1,3]}\n",
    "BF_in_NL_L = {4:[1,2],5:[1],6:[3],7:[]}\n",
    "I_in_k = {i : list(df_train[df_train['Species']== i].index) for i in range(len(classes))}\n",
    "my_W = {(i,j): 0.5 if i != j else 0 for i in classes_en for j in classes_en}\n",
    "index_instances = list(X_train.index)\n",
    "my_x = {(i,j): df_train.loc[i][j] for i in index_instances for j in index_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_in_NR(model, i):\n",
    "    if i==4:\n",
    "        return []\n",
    "    elif i==5:\n",
    "        return [2]\n",
    "    elif i==6:\n",
    "        return [1]\n",
    "    elif i==7:\n",
    "        return [1,3]\n",
    "def B_in_NL(model, i):\n",
    "    if i==4:\n",
    "        return [1,2]\n",
    "    elif i==5:\n",
    "        return [1]\n",
    "    elif i==6:\n",
    "        return [3]\n",
    "    elif i==7:\n",
    "        return []\n",
    "\n",
    "def I_k(model,i):\n",
    "    if i==0:\n",
    "        return I_in_k[0]\n",
    "    elif i==1:\n",
    "        return I_in_k[1]\n",
    "    elif i==2:\n",
    "        return I_in_k[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "We initialize the __model__ and the sets K, N_L, N_B, I, I_k, N_L_L, N_L_R and f_s are declared abstractly using the Set component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcreteModel() #ConcretModel()\n",
    "# Instances & Classes\n",
    "# Assume a dict I_in_k, with keys k and values of a list of I's in that k\n",
    "\n",
    "model.I = Set(initialize=set(i for k in I_in_k for i in I_in_k[k]))\n",
    "model.K = Set(initialize=I_in_k.keys())\n",
    "model.I_k = Set(model.K,initialize=I_k)    ##########################\n",
    "\n",
    "# Features\n",
    "model.f_s =Set(initialize=index_features)\n",
    "\n",
    "# Nodes Leaf N_L & Nodes Breanch N_B\n",
    "model.N_B = Set(initialize=set(i for k in BF_in_NL_R for i in BF_in_NL_R[k]))\n",
    "model.N_L = Set(initialize=BF_in_NL_R.keys())\n",
    "model.N_L_R = Set(model.N_L,initialize=B_in_NR)\n",
    "model.N_L_L = Set(model.N_L,initialize=B_in_NL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the model parameters are defined abstractly using the __Param__ component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost of misclassification\n",
    "model.W = Param(model.K, model.K, within=NonNegativeReals, initialize=my_W)\n",
    "\n",
    "# Value for the instance i-th of the feature j-th\n",
    "model.x = Param(model.I, model.f_s, within=PercentFraction, initialize=my_x)\n",
    "\n",
    "# Value for the lambda of local generalization\n",
    "model.lam_loc = Param(initialize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __Var__ component is used to define the decision variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random initialization\n",
    "init_a = np.random.uniform(low=-1.0, high=1.0, size=None)\n",
    "init_am = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_ap = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_mu = np.random.uniform(low=-1.0, high=1.0, size=None)\n",
    "init_C = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_P = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_p = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "\n",
    "# The weigths of feature j-th in breanch node t-th\n",
    "model.a = Var(model.f_s, model.N_B, within=Reals, bounds = (-1.0,1.0),initialize=init_a)\n",
    "\n",
    "#auxiliary variables for smooth version of regularization (local & global)\n",
    "model.a_minus = Var(model.f_s, model.N_B,  within = PercentFraction ,initialize=init_am)\n",
    "model.a_plus = Var(model.f_s, model.N_B,  within = PercentFraction,initialize=init_ap)\n",
    "\n",
    "# The intercepts of the linear combinations correspond to decision variables\n",
    "model.mu = Var(model.N_B, within = Reals, bounds = (-1.0,1.0),initialize=init_mu)\n",
    "\n",
    "# The variables thtat take into account if node t is labeled with class k\n",
    "model.C = Var(model.K, model.N_L, within = PercentFraction,initialize=init_C)\n",
    "\n",
    "# An auxiliary variables\n",
    "model.P = Var(model.I,model.N_L,within = PercentFraction,initialize=init_P)\n",
    "model.p = Var(model.I,model.N_B,within = PercentFraction,initialize=init_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several definition of functions: tools useful to characterize the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize the cost of misclassification\n",
    "def cost_rule(model):\n",
    "    return sum( sum( sum( model.P[i,t]* sum(model.W[k,j]*model.C[j,t] for j in model.K if k!=j)  for t in model.N_L) for i in model.I_k[k] ) for k in model.K ) + model.lam_loc*sum(sum(model.a_plus[j,tb]+model.a_minus[j,tb] for tb in model.N_B)for j in model.f_s)\n",
    "model.cost = Objective(rule=cost_rule, sense=minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must add the following set of constraints for making a single class prediction at each leaf node:\n",
    "def Pr(model,i,tl):\n",
    "    return  reduce(operator.mul,(model.p[i,t] for t in model.N_L_L[tl]),1)*reduce(operator.mul,(1-model.p[i,tr] for tr in model.N_L_R[tl]),1) == model.P[i,tl]\n",
    "model.Pr = Constraint(model.I,model.N_L, rule=Pr)\n",
    "\n",
    "def pr(model, i , tb):\n",
    "    return 1 / (1 + exp(-512*(   (sum(model.x[i,j]*model.a[j,tb]for j in model.f_s)/4)-model.mu[tb]  ))) ==model.p[i,tb]\n",
    "model.pr = Constraint(model.I,model.N_B, rule=pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, rule functions are used to define constraint expressions in the __Constraint__ component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must add the following set of constraints for making a single class prediction at each leaf node:\n",
    "def class_in_leaf(model, tl):\n",
    "    return  sum(model.C[k,tl] for k in model.K) == 1\n",
    "model.class_in_leaf = Constraint(model.N_L, rule=class_in_leaf)\n",
    "\n",
    "# We force each class k to be identified by, at least, one terminal node, by adding the set of constraints below:\n",
    "def leaf_in_class(model,k):\n",
    "    return sum(model.C[k,tl] for tl in model.N_L) >=1\n",
    "model.leaf_in_class = Constraint(model.K, rule=leaf_in_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following set of constraints unables to manage regularization\n",
    "def cuts_var(model,f,tb):\n",
    "    return model.a_plus[f,tb]-model.a_minus[f,tb]==model.a[f,tb]\n",
    "model.cuts = Constraint(model.f_s,model.N_B, rule=cuts_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.11.1: \n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "NOTE: You are using Ipopt by default with the MUMPS linear solver.\n",
      "      Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "\n",
      "This is Ipopt version 3.11.1, running with linear solver mumps.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:     3381\n",
      "Number of nonzeros in inequality constraint Jacobian.:       12\n",
      "Number of nonzeros in Lagrangian Hessian.............:     1165\n",
      "\n",
      "Total number of variables............................:      835\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:      835\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:      800\n",
      "Total number of inequality constraints...............:        3\n",
      "        inequality constraints with only lower bounds:        3\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 1.9272073e+002 1.31e+000 2.00e+000  -1.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 1.2365903e+002 8.39e-001 5.32e+000  -1.0 1.84e+000    -  7.13e-002 3.62e-001f  1\n",
      "   2 1.2214015e+002 8.27e-001 5.78e+001  -1.0 1.21e+000    -  6.02e-001 1.38e-002h  1\n",
      "   3 1.2212492e+002 8.27e-001 4.23e+005  -1.0 1.21e+000    -  1.00e+000 1.44e-004h  1\n",
      "   4r1.2212492e+002 8.27e-001 1.00e+003  -0.1 0.00e+000    -  0.00e+000 3.61e-007R  3\n",
      "   5r6.8289718e+001 3.19e-001 9.98e+002  -0.1 5.72e+002    -  2.32e-003 1.82e-003f  1\n",
      "   6 6.8288903e+001 3.19e-001 5.68e+004  -1.0 4.07e-001    -  6.10e-001 2.28e-005h  1\n",
      "   7r6.8288903e+001 3.19e-001 1.00e+003  -0.5 0.00e+000    -  0.00e+000 1.14e-007R  2\n",
      "   8r5.2778285e+001 1.99e-001 9.97e+002  -0.5 1.19e+002    -  4.86e-003 1.94e-003f  1\n",
      "   9 5.2777719e+001 1.99e-001 1.44e+005  -1.0 2.98e-001    -  7.64e-001 3.02e-005h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10r5.2777719e+001 1.99e-001 1.00e+003  -0.7 0.00e+000    -  0.00e+000 1.51e-007R  2\n",
      "  11r5.0194086e+001 9.90e-002 1.01e+003  -0.7 5.79e+001    -  1.71e-002 2.97e-003f  1\n",
      "  12 5.0192301e+001 9.90e-002 1.38e+005  -1.0 3.00e-001    -  7.83e-001 1.11e-004h  1\n",
      "  13r5.0192301e+001 9.90e-002 1.00e+003  -1.0 0.00e+000    -  0.00e+000 2.79e-007R  3\n",
      "  14r4.8394161e+001 5.06e-002 1.11e+003  -1.0 2.02e+001    -  4.08e-002 3.63e-003f  1\n",
      "  15 4.8390243e+001 5.06e-002 2.14e+005  -1.0 3.02e-001    -  7.81e-001 2.76e-004h  1\n",
      "  16r4.8390243e+001 5.06e-002 1.00e+003  -1.0 0.00e+000    -  0.00e+000 3.45e-007R  4\n",
      "  17r4.8219189e+001 2.08e-002 1.95e+003  -1.0 7.26e+000    -  1.17e-001 6.74e-003f  1\n",
      "  18 4.8188288e+001 2.07e-002 1.15e+005  -1.0 3.03e-001    -  7.80e-001 2.20e-003h  1\n",
      "  19 4.8188023e+001 2.07e-002 5.18e+009  -1.0 5.80e-001    -  1.00e+000 2.21e-005h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20r4.8188023e+001 2.07e-002 1.00e+003  -1.0 0.00e+000    -  0.00e+000 1.11e-007R  2\n",
      "  21r4.8015116e+001 9.74e-003 2.24e+003  -1.0 1.04e+000    -  1.18e-001 1.90e-002f  1\n",
      "  22 4.7476240e+001 9.36e-003 3.90e+004  -1.0 3.04e-001    -  7.80e-001 3.89e-002h  1\n",
      "  23 4.7471371e+001 9.36e-003 9.80e+007  -1.0 5.73e-001    -  1.00e+000 4.38e-004h  1\n",
      "  24r4.7471371e+001 9.36e-003 1.00e+003  -1.0 0.00e+000    -  0.00e+000 2.74e-007R  5\n",
      "  25r4.7489059e+001 1.70e-003 1.60e+003  -1.0 2.50e-001    -  1.86e-001 5.92e-002f  1\n",
      "  26 3.7820452e+001 4.56e-004 1.00e+003  -1.0 2.92e-001    -  7.92e-001 7.32e-001h  1\n",
      "  27 3.9454486e+001 4.55e-006 6.50e+002  -1.0 4.29e-001    -  1.00e+000 9.90e-001h  1\n",
      "  28 3.9369689e+001 2.37e-001 7.28e+013  -1.0 2.37e-001    -  9.50e-007 1.00e+000H  1\n",
      "MUMPS returned INFO(1) = -9 and requires more memory, reallocating.  Attempt 1\n",
      "  Increasing icntl[13] from 1000 to 2000.\n",
      "  29 3.9369875e+001 2.37e-001 7.28e+013  -1.0 5.04e-001   8.0 2.35e-003 2.45e-004h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30 3.9371221e+001 2.37e-001 7.28e+013  -1.0 2.70e+000   7.5 9.94e-002 2.02e-004h  1\n",
      "  31 3.9372906e+001 2.37e-001 7.26e+013  -1.0 4.54e-001   7.9 2.81e-003 2.40e-003h  1\n",
      "  32 3.9373029e+001 2.37e-001 7.26e+013  -1.0 5.44e-001   7.5 1.53e-003 9.41e-005h  1\n",
      "  33r3.9373029e+001 2.37e-001 1.00e+003  -0.6 0.00e+000   7.0 0.00e+000 4.73e-007R  4\n",
      "  34r3.9391862e+001 7.31e-002 9.97e+002  -0.6 2.37e+002    -  5.27e-002 9.87e-004f  1\n",
      "  35 3.9321418e+001 7.61e-003 5.94e+002  -1.0 1.02e-001    -  2.37e-002 1.00e+000f  1\n",
      "  36 3.9325917e+001 1.41e-005 1.73e+004  -1.0 5.27e-003   6.5 1.00e+000 1.00e+000h  1\n",
      "  37 3.9325919e+001 9.13e-011 1.04e+001  -1.0 9.46e-006   6.0 1.00e+000 1.00e+000h  1\n",
      "  38 3.9325918e+001 1.19e-012 3.85e-001  -1.0 1.05e-006   5.6 1.00e+000 1.00e+000f  1\n",
      "  39 3.9325281e+001 6.84e-013 1.60e+000  -1.7 1.31e-005   5.1 1.00e+000 1.00e+000f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  40 3.9323369e+001 6.16e-012 1.60e+000  -1.7 3.94e-005   4.6 1.00e+000 1.00e+000f  1\n",
      "  41 3.9317637e+001 5.54e-011 1.60e+000  -1.7 1.18e-004   4.1 1.00e+000 1.00e+000f  1\n",
      "  42 3.9300475e+001 4.99e-010 1.60e+000  -1.7 3.53e-004   3.7 1.00e+000 1.00e+000f  1\n",
      "  43 3.9249294e+001 4.49e-009 1.59e+000  -1.7 1.05e-003   3.2 1.00e+000 1.00e+000f  1\n",
      "  44 3.9098602e+001 4.05e-008 1.56e+000  -1.7 3.10e-003   2.7 1.00e+000 1.00e+000f  1\n",
      "  45 3.8674476e+001 3.66e-007 1.46e+000  -1.7 8.72e-003   2.2 1.00e+000 1.00e+000f  1\n",
      "  46 3.7706520e+001 3.35e-006 1.11e+000  -1.7 1.98e-002   1.7 1.00e+000 1.00e+000f  1\n",
      "  47 3.7298118e+001 3.21e-005 4.04e-001  -1.7 2.17e-002   1.3 1.00e+000 1.00e+000f  1\n",
      "  48 3.7114830e+001 3.96e-004 6.25e-001  -1.7 1.01e-001   0.8 1.00e+000 1.00e+000f  1\n",
      "  49 3.6609342e+001 6.87e-004 1.26e+000  -1.7 1.17e+000   0.3 6.89e-001 1.03e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  50 3.5956219e+001 8.83e-004 7.55e-001  -1.7 7.95e-002   0.7 1.00e+000 9.91e-001f  1\n",
      "  51 3.4330415e+001 6.02e-003 2.79e+000  -1.7 2.56e-001   0.3 1.00e+000 8.88e-001f  1\n",
      "  52 3.3529049e+001 1.21e-003 9.45e-001  -1.7 9.12e-002   0.7 1.00e+000 1.00e+000f  1\n",
      "  53 3.2429634e+001 2.62e-003 1.64e+000  -1.7 2.57e-001   0.2 1.00e+000 4.91e-001f  1\n",
      "  54 3.1657433e+001 1.16e-003 6.59e-001  -1.7 6.33e-002   0.6 1.00e+000 1.00e+000f  1\n",
      "  55 2.9697385e+001 7.05e-003 6.70e+000  -1.7 1.29e-001   0.2 1.00e+000 1.00e+000f  1\n",
      "  56 2.9073452e+001 1.28e-003 2.27e+000  -1.7 4.97e-002   0.6 1.00e+000 1.00e+000h  1\n",
      "  57 2.6490910e+001 8.21e-003 6.94e+001  -1.7 7.01e-001   0.1 7.38e-001 6.66e-001f  1\n",
      "  58 2.6190616e+001 8.26e-003 6.87e+001  -1.7 4.59e+000  -0.4 2.67e-002 1.71e-002f  1\n",
      "  59 2.5058203e+001 8.55e-003 4.54e+001  -1.7 2.15e-001   0.1 1.00e+000 4.25e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  60 2.2235439e+001 3.36e-002 4.85e+001  -1.7 5.80e-001    -  7.93e-001 3.70e-001f  1\n",
      "  61 2.0161469e+001 1.83e-002 1.89e+001  -1.7 1.32e-001    -  1.00e+000 1.00e+000h  1\n",
      "  62 1.9995053e+001 1.00e-003 1.36e+000  -1.7 2.57e-002    -  1.00e+000 1.00e+000h  1\n",
      "  63 1.9983442e+001 3.32e-006 6.34e-003  -1.7 5.45e-003    -  1.00e+000 1.00e+000h  1\n",
      "  64 1.6896085e+001 1.44e-002 2.77e+001  -3.8 2.89e-001    -  6.82e-001 3.45e-001f  1\n",
      "  65 1.6317539e+001 1.29e-002 1.08e+002  -3.8 3.28e-001    -  6.77e-001 1.09e-001f  1\n",
      "  66 1.4358155e+001 2.05e-002 1.22e+002  -3.8 2.06e-001    -  9.10e-001 4.57e-001f  1\n",
      "  67 1.2931640e+001 1.47e-002 5.61e+001  -3.8 1.24e-001    -  3.89e-001 4.88e-001f  1\n",
      "  68 1.2504673e+001 1.25e-002 4.56e+002  -3.8 1.44e-001    -  7.87e-001 2.28e-001h  1\n",
      "  69 1.1216637e+001 1.76e-002 1.28e+002  -3.8 1.16e-001    -  7.58e-001 7.41e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  70 1.0396694e+001 1.11e-002 6.87e+002  -3.8 7.08e-002    -  2.85e-001 6.25e-001f  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71 1.0198591e+001 9.92e-003 3.27e+002  -3.8 1.24e-001    -  2.18e-001 1.71e-001h  1\n",
      "  72 9.5194349e+000 1.44e-002 1.10e+003  -3.8 1.24e-001    -  4.43e-001 6.22e-001f  1\n",
      "  73 9.2337946e+000 1.17e-002 2.69e+002  -3.8 9.23e-002    -  3.44e-001 2.97e-001f  1\n",
      "  74 8.9717943e+000 8.59e-003 2.31e+003  -3.8 8.96e-002    -  4.81e-001 2.90e-001f  1\n",
      "  75 8.5519614e+000 5.68e-003 8.46e+002  -3.8 6.98e-002    -  3.51e-001 4.88e-001f  1\n",
      "  76 8.3300445e+000 4.74e-003 1.93e+004  -3.8 6.99e-002    -  1.00e+000 2.81e-001f  1\n",
      "  77 7.7649318e+000 5.08e-003 4.37e+003  -3.8 6.21e-002    -  2.07e-001 7.59e-001f  1\n",
      "  78 7.4954433e+000 4.31e-003 1.32e+004  -3.8 7.45e-002    -  7.46e-001 4.22e-001f  1\n",
      "  79 7.2444557e+000 3.22e-003 2.47e+004  -3.8 4.96e-002    -  2.13e-002 4.31e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  80 6.9580523e+000 2.85e-003 2.28e+004  -3.8 4.55e-002  -0.4 4.61e-001 5.24e-001f  1\n",
      "  81 6.5964329e+000 3.73e-003 4.84e+004  -3.8 6.24e-002    -  5.60e-001 7.35e-001f  1\n",
      "  82 6.4362857e+000 2.81e-003 1.18e+005  -3.8 6.38e-002    -  1.68e-001 3.45e-001f  1\n",
      "  83 6.2973200e+000 2.50e-003 2.84e+004  -3.8 1.17e-001    -  4.57e-001 3.17e-001f  1\n",
      "  84 6.2100394e+000 2.20e-003 2.90e+005  -3.8 7.03e-002    -  5.24e-001 2.12e-001h  1\n",
      "  85 5.8533573e+000 5.71e-003 1.41e+005  -3.8 8.42e-002    -  1.00e+000 8.64e-001f  1\n",
      "  86 5.7531049e+000 4.42e-003 2.00e+006  -3.8 6.57e-002    -  4.72e-002 2.53e-001f  1\n",
      "  87 5.6605372e+000 4.43e-003 3.98e+007  -3.8 6.48e-002    -  1.03e-002 2.73e-001f  1\n",
      "  88 5.6538159e+000 4.61e-003 3.90e+007  -3.8 4.30e-001   0.0 5.31e-003 2.00e-002f  1\n",
      "  89 5.6110917e+000 4.42e-003 3.41e+007  -3.8 4.32e-002   0.4 1.93e-001 1.26e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  90 5.5348554e+000 3.69e-003 2.43e+007  -3.8 2.94e-002   0.9 4.87e-002 2.86e-001h  1\n",
      "  91 5.4026551e+000 2.45e-003 1.28e+007  -3.8 2.52e-002   1.3 2.63e-001 4.75e-001f  1\n",
      "  92 5.1863677e+000 1.29e-003 4.80e+005  -3.8 2.06e-002   1.7 5.62e-002 9.93e-001f  1\n",
      "  93 5.1624972e+000 1.97e-003 2.57e+005  -3.8 2.31e-002   1.2 1.18e-001 5.31e-001f  1\n",
      "  94 5.0773145e+000 1.69e-003 1.93e+005  -3.8 7.40e-002   0.8 9.12e-001 1.44e-001f  1\n",
      "  95 5.0558539e+000 1.59e-003 1.83e+005  -3.8 6.46e-002   0.3 1.00e+000 6.06e-002h  1\n",
      "  96 4.9462683e+000 1.37e-003 1.25e+005  -3.8 7.43e-002  -0.2 7.25e-001 3.21e-001f  1\n",
      "  97 4.8626851e+000 3.90e-003 1.05e+005  -3.8 3.91e-001  -0.7 1.57e-001 1.61e-001f  1\n",
      "  98 4.6901176e+000 1.16e-002 3.53e+004  -3.8 1.84e-001    -  6.87e-001 7.53e-001f  1\n",
      "  99 4.6427567e+000 9.87e-003 1.25e+005  -3.8 2.07e-001    -  3.65e-001 1.73e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      " 100 4.5626505e+000 8.08e-003 7.97e+005  -3.8 1.82e-001    -  1.00e+000 3.71e-001h  1\n",
      " 101 4.3889366e+000 6.94e-003 3.64e+001  -3.8 1.10e-001    -  1.00e+000 1.00e+000h  1\n",
      " 102 4.3446464e+000 5.61e-003 2.49e+005  -3.8 7.37e-002    -  2.33e-001 2.02e-001h  1\n",
      " 103 4.2515057e+000 1.85e-002 2.87e+007  -3.8 3.10e-001    -  6.84e-002 4.44e-001f  1\n",
      " 104 4.1990378e+000 1.67e-002 2.43e+007  -3.8 2.51e-001    -  7.73e-001 1.65e-001f  1\n",
      " 105 4.0926244e+000 9.16e-003 9.14e+006  -3.8 7.17e-002    -  1.52e-001 6.87e-001h  1\n",
      " 106 3.9641898e+000 1.43e-002 7.38e+005  -3.8 1.01e-001    -  5.83e-001 1.00e+000f  1\n",
      " 107 3.9075297e+000 1.18e-002 6.62e+005  -3.8 1.66e-001    -  1.42e-001 1.75e-001h  1\n",
      " 108 3.8484188e+000 9.39e-003 1.53e+007  -3.8 1.29e-001    -  1.00e+000 2.07e-001f  1\n",
      " 109 3.7479052e+000 1.88e-002 4.98e+007  -3.8 2.36e-001    -  1.79e-001 4.86e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      " 110 3.7365518e+000 1.84e-002 4.88e+007  -3.8 3.68e-001    -  1.88e-002 2.14e-002h  1\n",
      " 111 3.7386097e+000 1.83e-002 4.83e+007  -3.8 5.07e-001    -  3.15e-002 7.82e-003h  1\n",
      " 112 3.6819791e+000 8.09e-003 2.23e+007  -3.8 8.88e-002    -  4.70e-005 5.58e-001f  1\n",
      " 113 3.5417660e+000 1.31e-002 3.58e+006  -3.8 1.31e-001    -  5.54e-001 1.00e+000f  1\n",
      " 114 3.5003875e+000 1.11e-002 2.07e+007  -3.8 1.01e-001    -  9.85e-001 1.83e-001h  1\n",
      " 115 3.4678103e+000 1.01e-002 4.05e+007  -3.8 1.21e-001    -  1.00e+000 1.06e-001h  1\n",
      " 116 3.4563367e+000 9.81e-003 2.66e+007  -3.8 2.89e-001    -  1.22e-001 2.89e-002h  1\n",
      " 117 3.3843053e+000 2.04e-002 3.80e+007  -3.8 6.11e-001    -  1.33e-001 1.84e-001f  1\n",
      " 118 3.3494934e+000 7.27e-003 4.69e+007  -3.8 7.10e-002    -  6.46e-003 1.00e+000f  1\n",
      " 119 3.3016756e+000 8.62e-003 1.68e+007  -3.8 1.21e-001    -  1.00e+000 6.43e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      " 120 3.2691854e+000 6.12e-003 9.98e+003  -3.8 5.17e-002    -  2.84e-001 1.00e+000f  1\n",
      " 121 3.2369393e+000 8.93e-003 9.22e+003  -3.8 1.19e-001    -  1.00e+000 5.85e-001h  1\n",
      " 122 3.2317235e+000 6.61e-003 1.27e+004  -3.8 5.46e-002    -  2.93e-001 1.00e+000h  1\n",
      " 123 3.2216589e+000 5.30e-003 7.58e+003  -3.8 2.83e-002    -  8.96e-001 1.00e+000h  1\n",
      " 124 3.2328590e+000 3.33e-003 1.15e+004  -3.8 2.91e-002    -  6.59e-001 1.00e+000h  1\n",
      " 125 3.2356095e+000 1.44e-004 1.36e-001  -3.8 6.13e-003    -  1.00e+000 1.00e+000h  1\n",
      " 126 3.2361042e+000 4.86e-006 2.26e-003  -3.8 1.15e-003    -  1.00e+000 1.00e+000h  1\n",
      " 127 3.2168225e+000 3.55e-004 5.68e+003  -5.7 1.81e-002    -  8.68e-001 4.86e-001f  1\n",
      " 128 3.2092569e+000 2.98e-004 2.15e+003  -5.7 1.09e-002    -  9.95e-001 7.56e-001h  1\n",
      " 129 3.2094978e+000 2.00e-004 1.10e+003  -5.7 8.47e-003    -  1.34e-001 5.21e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      " 130 3.2100592e+000 1.23e-004 7.41e+002  -5.7 7.67e-003    -  3.45e-001 1.00e+000h  1\n",
      " 131 3.2110098e+000 8.38e-005 1.41e+004  -5.7 7.96e-003    -  1.02e-001 1.00e+000h  1\n",
      " 132 3.2105341e+000 4.89e-005 3.67e+002  -5.7 6.38e-003    -  5.40e-001 1.00e+000h  1\n",
      " 133 3.2107699e+000 1.06e-005 7.30e+001  -5.7 2.37e-003    -  7.59e-001 1.00e+000h  1\n",
      " 134 3.2108456e+000 4.72e-008 1.12e-004  -5.7 1.19e-004    -  1.00e+000 1.00e+000h  1\n",
      " 135 3.2108459e+000 2.80e-012 2.20e-009  -5.7 9.29e-007    -  1.00e+000 1.00e+000h  1\n",
      " 136 3.2107813e+000 4.48e-007 3.64e+000  -8.6 3.01e-004    -  9.97e-001 9.77e-001f  1\n",
      "In iteration 136, 1 Slack too small, adjusting variable bound\n",
      " 137 3.2107829e+000 2.23e-007 5.79e+000  -8.6 8.34e-006    -  9.35e-001 5.01e-001h  1\n",
      "In iteration 137, 2 Slacks too small, adjusting variable bounds\n",
      " 138 3.2107840e+000 7.89e-008 2.40e+000  -8.6 4.16e-006    -  1.00e+000 6.47e-001h  1\n",
      " 139 3.2107846e+000 1.19e-011 1.07e-007  -8.6 1.47e-006    -  1.00e+000 1.00e+000h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      " 140 3.2107846e+000 3.33e-016 1.55e-013  -8.6 1.61e-009    -  1.00e+000 1.00e+000h  1\n",
      "\n",
      "Number of Iterations....: 140\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  3.2107846071400616e+000   3.2107846071400616e+000\n",
      "Dual infeasibility......:  1.5543213048084208e-013   1.5543213048084208e-013\n",
      "Constraint violation....:  3.3306690738754696e-016   3.3306690738754696e-016\n",
      "Complementarity.........:  2.5743147774988260e-009   2.5743147774988260e-009\n",
      "Overall NLP error.......:  2.5743147774988260e-009   2.5743147774988260e-009\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 167\n",
      "Number of objective gradient evaluations             = 141\n",
      "Number of equality constraint evaluations            = 167\n",
      "Number of inequality constraint evaluations          = 167\n",
      "Number of equality constraint Jacobian evaluations   = 149\n",
      "Number of inequality constraint Jacobian evaluations = 149\n",
      "Number of Lagrangian Hessian evaluations             = 140\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      3.167\n",
      "Total CPU secs in NLP function evaluations           =      0.146\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    }
   ],
   "source": [
    "opt = SolverFactory('ipopt',executable='C:/.../ipopt.exe')# in executable the directory path of ipopt.exe\n",
    "# Create a model instance and optimize\n",
    "#instance = model.create_instance()\n",
    "results = opt.solve(model,tee=True)\n",
    "#instance.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: \n",
      "- Lower bound: -inf\n",
      "  Upper bound: inf\n",
      "  Number of objectives: 1\n",
      "  Number of constraints: 803\n",
      "  Number of variables: 835\n",
      "  Sense: unknown\n",
      "Solver: \n",
      "- Status: ok\n",
      "  Message: Ipopt 3.11.1\\x3a Optimal Solution Found\n",
      "  Termination condition: optimal\n",
      "  Id: 0\n",
      "  Error rc: 0\n",
      "  Time: 3.4046006202697754\n",
      "Solution: \n",
      "- number of solutions: 0\n",
      "  number of solutions displayed: 0\n",
      "\n",
      "3.210785439460926\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(value(model.cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several definition of functions: tools useful to deal with __Test Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store the variables results\n",
    "def extraction_va(model):\n",
    "    \n",
    "    mu = {str(model.mu[i]): model.mu[i].value for i in model.mu}\n",
    "    a = {str(model.a[i]): model.a[i].value for i in model.a}\n",
    "    C = {str(model.C[i]): model.C[i].value for i in model.C}\n",
    "    \n",
    "    return {'mu': mu,'a':a ,'C':C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sigmoid(a,x,mu,scale=512):\n",
    "    l = len(x)\n",
    "    val = (sum([a[i]*x   for i, x in enumerate(x)]) / l) - mu \n",
    "    # The default value is 512 as suggested in Blanquero et Al.\n",
    "    return 1 / (1 + math.exp(-scale*val))\n",
    "\n",
    "# An easy way to manage product within elements of an iterable object\n",
    "def multiply_numpy(iterable):\n",
    "    return np.prod(np.array(iterable))\n",
    "\n",
    "# Calculate the probability of an individual falling into a given leaf node:\n",
    "def Prob(model,var,x, leaf_idx):\n",
    "    left = [my_sigmoid(list(var['a']['a['+str(i)+','+str(tl)+']'] for i in index_features),x,var['mu']['mu['+str(tl)+']']) for tl in model.N_L_L[leaf_idx] ]\n",
    "    right = [1-my_sigmoid(list(var['a']['a['+str(i)+','+str(tr)+']'] for i in index_features),x,var['mu']['mu['+str(tr)+']']) for tr in model.N_L_R[leaf_idx] ]\n",
    "    return multiply_numpy(left)*multiply_numpy(right)\n",
    "\n",
    "#Calculate the predicted label of a single instance\n",
    "def comp_label(model,x,var):\n",
    "    prob ={k : sum(Prob(model,var,x,i)*var['C']['C['+str(k)+','+str(i)+']'] for i in model.N_L) for k in model.K}\n",
    "    return int(max(prob, key=prob.get))\n",
    "\n",
    "#Generate a list of predicted labels for the test set\n",
    "def predicted_lab(model,X_test,var):\n",
    "    label = []\n",
    "    for i in range(0,len(X_test)):\n",
    "        label.append(comp_label(model,list(X_test.iloc[i]),var))\n",
    "    return label\n",
    "\n",
    "#Calculate the accuracy out of sample\n",
    "def accuracy(y,y_pred):\n",
    "    l = [1 if y[i]==y_pred[i] else 0 for i in range(0,len(y))]\n",
    "    return sum(l)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 10,  3],\n",
       "       [ 0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = extraction_va(model)\n",
    "y_pred = predicted_lab(model,X_test,var)\n",
    "yy= list(y_test)\n",
    "print(accuracy(yy,y_pred))\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.mu:\n",
    "    print (str(model.mu[i]), model.mu[i].value)\n",
    "for i in model.P:\n",
    "    print (str(model.P[i]), model.P[i].value)\n",
    "for i in model.p:\n",
    "    print(str(model.C[i]),model.C[i].value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
